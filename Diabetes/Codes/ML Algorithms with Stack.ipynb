{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>No_Pation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177</td>\n",
       "      <td>45364</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>4.6</td>\n",
       "      <td>70</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147</td>\n",
       "      <td>45365</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735</td>\n",
       "      <td>34221</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>62</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>45416</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>7.5</td>\n",
       "      <td>79</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>34222</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>4.1</td>\n",
       "      <td>73</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>165</td>\n",
       "      <td>45412</td>\n",
       "      <td>F</td>\n",
       "      <td>77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>106</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>186</td>\n",
       "      <td>454316</td>\n",
       "      <td>M</td>\n",
       "      <td>77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>106</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>339</td>\n",
       "      <td>5980</td>\n",
       "      <td>M</td>\n",
       "      <td>77</td>\n",
       "      <td>6.2</td>\n",
       "      <td>99</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>389</td>\n",
       "      <td>24101</td>\n",
       "      <td>M</td>\n",
       "      <td>77</td>\n",
       "      <td>6.2</td>\n",
       "      <td>99</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>171</td>\n",
       "      <td>42329</td>\n",
       "      <td>F</td>\n",
       "      <td>79</td>\n",
       "      <td>5.2</td>\n",
       "      <td>54</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  No_Pation Gender  AGE  Urea   Cr  HbA1c  Chol   TG  HDL  LDL  VLDL  \\\n",
       "0    177      45364      F   20   4.6   70    9.6   4.1  1.8  1.0  2.3   0.8   \n",
       "1    147      45365      F   25  10.0   35    4.0   4.3  3.5  0.8  1.3   0.8   \n",
       "2    735      34221      M   26   4.5   62    4.9   3.7  1.4  1.1  2.1   0.6   \n",
       "3    129      45416      M   26   7.5   79    8.8   3.5  2.0  2.0  0.9   0.5   \n",
       "4     67      34222      F   28   4.1   73    4.9   5.3  3.2  0.8  0.8   0.9   \n",
       "..   ...        ...    ...  ...   ...  ...    ...   ...  ...  ...  ...   ...   \n",
       "995  165      45412      F   77   5.0  106    5.4   3.9  2.1  1.2  4.2   1.1   \n",
       "996  186     454316      M   77   5.0  106    5.4   0.0  2.8  0.8  1.8   0.7   \n",
       "997  339       5980      M   77   6.2   99    7.2   3.2  1.1  0.8  2.0   0.5   \n",
       "998  389      24101      M   77   6.2   99    7.2   3.2  1.1  0.8  2.0   0.5   \n",
       "999  171      42329      F   79   5.2   54    9.2   6.4  3.0  1.1  4.1   1.3   \n",
       "\n",
       "      BMI CLASS  \n",
       "0    30.0     Y  \n",
       "1    22.0     N  \n",
       "2    23.0     N  \n",
       "3    28.0     Y  \n",
       "4    24.0     Y  \n",
       "..    ...   ...  \n",
       "995  24.0     N  \n",
       "996  19.0     N  \n",
       "997  29.0     Y  \n",
       "998  29.0     Y  \n",
       "999  30.0     Y  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../Dataset/Diabetes_Dataset.csv')\n",
    "data\n",
    "\n",
    "# Assume that you are trying to predict a multi-class outcome variable 'y' based on some features 'X1', 'X2', 'X3'\n",
    "# X = df[['AGE','Urea', 'Cr', 'HbA1c','Chol','TG','HDL','LDL','VLDL','BMI']]\n",
    "# y = df['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Gaussian Naive Bayes ===\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.9327318776235067\n",
      "Kappa Score: 0.7896434456403605\n",
      "Precision: 0.9326480829748804\n",
      "Recall: 0.9333333333333333\n",
      "\n",
      "=== Decision Tree ===\n",
      "Accuracy: 0.9833333333333333\n",
      "F1 Score: 0.9833385833899071\n",
      "Kappa Score: 0.9466135174573798\n",
      "Precision: 0.9833938417472253\n",
      "Recall: 0.9833333333333333\n",
      "\n",
      "=== SVM ===\n",
      "Accuracy: 0.82\n",
      "F1 Score: 0.7389010989010989\n",
      "Kappa Score: 0.0\n",
      "Precision: 0.6724\n",
      "Recall: 0.82\n",
      "\n",
      "=== AdaBoost ===\n",
      "Accuracy: 0.9066666666666666\n",
      "F1 Score: 0.8870683760683761\n",
      "Kappa Score: 0.6129032258064517\n",
      "Precision: 0.9095377128953771\n",
      "Recall: 0.9066666666666666\n",
      "\n",
      "=== LDA ===\n",
      "Accuracy: 0.89\n",
      "F1 Score: 0.8799492666631871\n",
      "Kappa Score: 0.6474358974358974\n",
      "Precision: 0.8740744535519127\n",
      "Recall: 0.89\n",
      "\n",
      "=== Perceptron ===\n",
      "Accuracy: 0.84\n",
      "F1 Score: 0.7992727272727272\n",
      "Kappa Score: 0.278629395852119\n",
      "Precision: 0.7800945626477541\n",
      "Recall: 0.84\n",
      "\n",
      "=== KNN ===\n",
      "Accuracy: 0.8733333333333333\n",
      "F1 Score: 0.8668726418353949\n",
      "Kappa Score: 0.567050244958414\n",
      "Precision: 0.8612431771127423\n",
      "Recall: 0.8733333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9733333333333334\n",
      "F1 Score: 0.9712528115159693\n",
      "Kappa Score: 0.9123063431745104\n",
      "Precision: 0.9704762889440309\n",
      "Recall: 0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Gradient Boosting ===\n",
      "Accuracy: 0.9833333333333333\n",
      "F1 Score: 0.9817374137992639\n",
      "Kappa Score: 0.9465450269056698\n",
      "Precision: 0.9803146694575265\n",
      "Recall: 0.9833333333333333\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.9166666666666666\n",
      "F1 Score: 0.9033115592161317\n",
      "Kappa Score: 0.7037797701331017\n",
      "Precision: 0.8971400778210117\n",
      "Recall: 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Extra Trees ===\n",
      "Accuracy: 0.9533333333333334\n",
      "F1 Score: 0.9504352437067868\n",
      "Kappa Score: 0.8403102543629519\n",
      "Precision: 0.950068134763787\n",
      "Recall: 0.9533333333333334\n",
      "\n",
      "=== Bagging ===\n",
      "Accuracy: 0.9833333333333333\n",
      "F1 Score: 0.9817374137992639\n",
      "Kappa Score: 0.9465450269056698\n",
      "Precision: 0.9803146694575265\n",
      "Recall: 0.9833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "# Features and target\n",
    "X = data[['AGE','Urea', 'Cr', 'HbA1c','Chol','TG','HDL','LDL','VLDL','BMI']]\n",
    "y = data['CLASS']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# ===============================\n",
    "# Reusable Evaluation Function\n",
    "# ===============================\n",
    "def evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# ===============================\n",
    "# Model Calls\n",
    "# ===============================\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "evaluate_model(GaussianNB(), \"Gaussian Naive Bayes\")\n",
    "evaluate_model(DecisionTreeClassifier(), \"Decision Tree\")\n",
    "evaluate_model(SVC(), \"SVM\")\n",
    "evaluate_model(AdaBoostClassifier(), \"AdaBoost\")\n",
    "evaluate_model(LinearDiscriminantAnalysis(), \"LDA\")\n",
    "evaluate_model(Perceptron(), \"Perceptron\")\n",
    "evaluate_model(KNeighborsClassifier(), \"KNN\")\n",
    "evaluate_model(RandomForestClassifier(), \"Random Forest\")\n",
    "evaluate_model(GradientBoostingClassifier(), \"Gradient Boosting\")\n",
    "evaluate_model(LogisticRegression(max_iter=1000), \"Logistic Regression\")\n",
    "evaluate_model(ExtraTreesClassifier(), \"Extra Trees\")\n",
    "evaluate_model(BaggingClassifier(), \"Bagging\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost:  0.995\n",
      "F1 Score for XGBoost:  0.995056727932834\n",
      "Kappa Score for XGBoost: 0.9814281734608599\n",
      "Precision for XGBoost:  0.9952500000000001\n",
      "Recall for XGBoost:  0.995\n"
     ]
    }
   ],
   "source": [
    "# XGBoost BEFORE FEATURE SELECTION\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "\n",
    "data = pd.get_dummies(data, columns=['Gender'])\n",
    "\n",
    "X = data.drop('CLASS', axis=1)\n",
    "y = data['CLASS']\n",
    "# Remove leading/trailing spaces\n",
    "y = y.str.strip()\n",
    "\n",
    "# Convert categorical variable to numerical\n",
    "y = y.map({'N': 0, 'P': 1, 'Y': 2})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Assuming y_test are your true classes and y_pred are your predicted classes\n",
    "\n",
    "# Accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for XGBoost: \", accuracy)\n",
    "\n",
    "# F1 Score\n",
    "f1_score = metrics.f1_score(y_test, y_pred, average='weighted') # you can change the average parameter to 'micro', 'macro', 'weighted', depending on your problem\n",
    "print(\"F1 Score for XGBoost: \", f1_score)\n",
    "\n",
    "# Kappa Score\n",
    "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Kappa Score for XGBoost:\", kappa_score)\n",
    "\n",
    "# Precision\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted') # you can change the average parameter to 'micro', 'macro', 'weighted', depending on your problem\n",
    "print(\"Precision for XGBoost: \", precision)\n",
    "\n",
    "# Recall\n",
    "recall = metrics.recall_score(y_test, y_pred, average='weighted') # you can change the average parameter to 'micro', 'macro', 'weighted', depending on your problem\n",
    "print(\"Recall for XGBoost: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995\n",
      "Precision: 0.9952500000000001\n",
      "Recall: 0.995\n",
      "F1-Score: 0.995056727932834\n",
      "Kappa Index: 0.9814281734608599\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier #inbuilt library in sklearn for stacking classifier \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score #Evaluation metrics\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Trees\n",
    "from sklearn.svm import SVC #Support Vector\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis #LDA\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression # Perceptron and Logistic Regression. Logistic Regression is also used as meta classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bayes\n",
    "from xgboost import XGBClassifier # Only algorithm which was not inbuilt in sklearn library \n",
    "from sklearn.preprocessing import LabelEncoder # Used for sorting error which was constantly appearing of the target variable\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\DiabetesData\\Diabetes_Dataset.csv')\n",
    "\n",
    "X = df[['AGE','Urea', 'Cr', 'HbA1c','Chol','TG','HDL','LDL','VLDL','BMI']] #The attributes which are used for analysis\n",
    "y = df['CLASS'] # Target \n",
    "\n",
    "# The next 3 lines of code is due to inferring invalid classes from unique values (the error mentioned above)\n",
    "# Remove leading and trailing spaces\n",
    "y = y.str.strip()\n",
    "\n",
    "# Create a label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform 'y'\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the base classifiers\n",
    "base_classifiers = [\n",
    "    ('dt', DecisionTreeClassifier()), #Decision Trees\n",
    "    ('svm', SVC()), #Support Vector Machine/Classifier\n",
    "    ('ada', AdaBoostClassifier()), #AdaBoost\n",
    "    ('xgb', XGBClassifier()), #XGBoost\n",
    "    ('lda', LinearDiscriminantAnalysis()), #LDA\n",
    "    ('per', Perceptron()), #Perceptron\n",
    "    ('knn', KNeighborsClassifier()), #KNN\n",
    "    ('gnb', GaussianNB()), #K Nearest Neighbor\n",
    "    ('rf', RandomForestClassifier()), #Random Forests\n",
    "    ('gb', GradientBoostingClassifier()), # Gradient Boosting\n",
    "    ('lr', LogisticRegression(max_iter=10000)), #Logistic Regression. Maximum Iterations increased and specified\n",
    "    ('et', ExtraTreesClassifier()), # ExtraTrees\n",
    "    ('bag', BaggingClassifier()) # Bagging \n",
    "]\n",
    "\n",
    "# Initialize the stacking classifier - Basically here we create a class called stacking_clf \n",
    "stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=LogisticRegression(max_iter=10000))\n",
    "\n",
    "# Train the classifiers\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1-Score:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('Kappa Index:', cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19   0   0]\n",
      " [  0  11   0]\n",
      " [  1   0 169]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_test are your true labels and y_pred are the predicted labels\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
